{"cells":[{"cell_type":"markdown","metadata":{"id":"TAyzWDzFdnLa"},"source":["## Классификация текстов: Spam or Ham"]},{"cell_type":"markdown","metadata":{"id":"sh91cKPmdnLb"},"source":["В этом задании на примере классического датасета Spambase Dataset (https://archive.ics.uci.edu/ml/datasets/spambase) мы попробуем сделать свой спам-фильтр c помощью библиотеки scikit-learn. Датасет содержит корпус текстов 5,574 смс с метками \"spam\" и \"ham\". "]},{"cell_type":"markdown","metadata":{"id":"D4Bf-AmgdnLb"},"source":["### Данные"]},{"cell_type":"markdown","metadata":{"id":"lWvXDXKrdnLb"},"source":["Для удобства данные приложены в описании задания"]},{"cell_type":"code","execution_count":183,"metadata":{"id":"UnJwvQzbdnLb"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('datasets/3_data.csv', encoding='latin-1')"]},{"cell_type":"code","execution_count":184,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>spam</td>\n","      <td>This is the 2nd time we have tried 2 contact u...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>ham</td>\n","      <td>Will Ì_ b going to esplanade fr home?</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5569</th>\n","      <td>ham</td>\n","      <td>Pity, * was in mood for that. So...any other s...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5570</th>\n","      <td>ham</td>\n","      <td>The guy did some bitching but I acted like i'd...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5571</th>\n","      <td>ham</td>\n","      <td>Rofl. Its true to its name</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5572 rows × 5 columns</p>\n","</div>"],"text/plain":["        v1                                                 v2 Unnamed: 2  \\\n","0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n","1      ham                      Ok lar... Joking wif u oni...        NaN   \n","2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n","3      ham  U dun say so early hor... U c already then say...        NaN   \n","4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n","...    ...                                                ...        ...   \n","5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n","5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n","5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n","5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n","5571   ham                         Rofl. Its true to its name        NaN   \n","\n","     Unnamed: 3 Unnamed: 4  \n","0           NaN        NaN  \n","1           NaN        NaN  \n","2           NaN        NaN  \n","3           NaN        NaN  \n","4           NaN        NaN  \n","...         ...        ...  \n","5567        NaN        NaN  \n","5568        NaN        NaN  \n","5569        NaN        NaN  \n","5570        NaN        NaN  \n","5571        NaN        NaN  \n","\n","[5572 rows x 5 columns]"]},"execution_count":184,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"GRqzedIIdnLc"},"source":["Оставляем только интересующие нас колонки — тексты смс и метки:"]},{"cell_type":"code","execution_count":185,"metadata":{"id":"xO59-HEadnLc","outputId":"470c6b7d-6e6f-4105-eab4-947debd213ef"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  label                                               text\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."]},"execution_count":185,"metadata":{},"output_type":"execute_result"}],"source":["df = df[['v1', 'v2']]\n","df = df.rename(columns = {'v1': 'label', 'v2': 'text'})\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"NU2xwmvIdnLd"},"source":["Удаляем дублирующиеся тексты:"]},{"cell_type":"code","execution_count":186,"metadata":{"id":"iveCG_bXdnLd"},"outputs":[],"source":["df = df.drop_duplicates('text')"]},{"cell_type":"markdown","metadata":{"id":"XuPip3mzdnLd"},"source":["Заменяем метки на бинарные:"]},{"cell_type":"code","execution_count":187,"metadata":{"id":"JsKdfy6-dnLd"},"outputs":[],"source":["df['label'] = df['label'].map({'ham': 0, 'spam': 1})"]},{"cell_type":"markdown","metadata":{"id":"8vQJK8LNdnLe"},"source":["### Предобработка текста (Задание 1)"]},{"cell_type":"markdown","metadata":{"id":"D8tefVdTdnLe"},"source":["Нужно дополнить функцию для предобработки сообщений, которая делает с текстом следующее:\n","* приводит текст к нижнему регистру;\n","* удаляет стоп-слова;\n","* удаляет знаки препинания;\n","* нормализует текст при помощи стеммера Snowball.\n","\n","Предлагаем воспользоваться библиотекой nltk, чтобы не составлять список стоп-слов и не реализовывать алгоритм стемминга самостоятельно. Примеры использования стеммеров можно найти по ссылке (https://www.nltk.org/howto/stem.html)."]},{"cell_type":"code","execution_count":188,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\eugen\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":188,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":189,"metadata":{"id":"yhU1BvAHdnLe"},"outputs":[],"source":["from nltk import stem\n","from nltk.corpus import stopwords\n","import re\n","\n","stemmer = stem.SnowballStemmer('english')\n","stopwords = set(stopwords.words('english'))\n","\n","def preprocess(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    text = text.lower()\n","    text = text.split()\n","    arr = []\n","    for i in range(len(text)):\n","      \tif text[i] not in stopwords:\n","          text[i] = stemmer.stem(text[i])\n","          arr.append(text[i])\n","    return ' '.join(arr)"]},{"cell_type":"markdown","metadata":{"id":"QM-Lrt6ddnLe"},"source":["Проверка, что функция работает верно"]},{"cell_type":"code","execution_count":190,"metadata":{"id":"RSuPqUb2dnLe"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":190,"metadata":{},"output_type":"execute_result"}],"source":["preprocess(\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\") == \"im gonna home soon dont want talk stuff anymor tonight k ive cri enough today\"\n","preprocess(\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\") == \"go jurong point crazi avail bugi n great world la e buffet cine got amor wat\""]},{"cell_type":"markdown","metadata":{"id":"84H8mOmpdnLe"},"source":["Применяем получившуюся функцию к текстам:"]},{"cell_type":"code","execution_count":191,"metadata":{"id":"NtM4626ednLe"},"outputs":[],"source":["df['text'] = df['text'].apply(preprocess)"]},{"cell_type":"code","execution_count":192,"metadata":{},"outputs":[{"data":{"text/plain":["0       go jurong point crazi avail bugi n great world...\n","1                                   ok lar joke wif u oni\n","2       free entri 2 wkli comp win fa cup final tkts 2...\n","3                     u dun say earli hor u c alreadi say\n","4               nah dont think goe usf live around though\n","                              ...                        \n","5567    2nd time tri 2 contact u u å750 pound prize 2 ...\n","5568                             ì_ b go esplanad fr home\n","5569                              piti mood soani suggest\n","5570    guy bitch act like id interest buy someth els ...\n","5571                                       rofl true name\n","Name: text, Length: 5169, dtype: object"]},"execution_count":192,"metadata":{},"output_type":"execute_result"}],"source":["df['text']"]},{"cell_type":"markdown","metadata":{"id":"gRyqtqUtdnLe"},"source":["### Разделение данных на обучающую и тестовую выборки (Задание 2)"]},{"cell_type":"code","execution_count":193,"metadata":{"id":"nt7Z5NCMdnLe"},"outputs":[],"source":["X = df['text']\n","y = df['label'].values"]},{"cell_type":"markdown","metadata":{"id":"6r4PJBctdnLe"},"source":["Теперь нужно разделить данные на тестовую (test) и обучающую (train) выборку. В библиотеке scikit-learn для этого есть готовые инструменты."]},{"cell_type":"code","execution_count":195,"metadata":{"id":"r1c9ARWIdnLe"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)"]},{"cell_type":"markdown","metadata":{"id":"KOV7Ub4ldnLe"},"source":["### Обучение классификатора (Задание 3)"]},{"cell_type":"markdown","metadata":{"id":"enAzNefqdnLe"},"source":["Переходим к обучению классификатора.\n","\n","Сначала извлекаем признаки из текстов. Рекомендуем попробовать разные способы и посмотреть, как это влияет на результат (подробнее о различных способах представления текстов можно прочитать по ссылке https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction).\n","\n","Затем обучаем классификатор. Мы используем SVM, но можно поэкспериментировать с различными алгоритмами."]},{"cell_type":"code","execution_count":196,"metadata":{"id":"QtfcmJ7NdnLe"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","\n","# извлекаем признаки из текстов\n","vectorizer = TfidfVectorizer(decode_error='ignore')\n","X_train = vectorizer.fit_transform(X_train)\n","X_test = vectorizer.transform(X_test)"]},{"cell_type":"code","execution_count":197,"metadata":{"id":"PIQQo8j3dnLe"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\eugen\\anaconda3\\envs\\Education\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n","  warnings.warn(\n"]}],"source":["from sklearn.svm import LinearSVC\n","from sklearn.metrics import classification_report\n","\n","#обучаем подель SVM\n","\n","model = LinearSVC(random_state = 41, C = 1.1)\n","model.fit(X_train, y_train)\n","predictions = model.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"sn9kvQaZdnLe"},"source":["Для самопроверки. Если вы верно дополнили функцию ```preprocess```, то должны получиться следующие результаты оценки модели."]},{"cell_type":"code","execution_count":198,"metadata":{"id":"zGxDEYnjdnLe","outputId":"104a68f1-cf8a-421e-cc3f-2b63b99c2520"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0      0.977     0.994     0.986       898\n","           1      0.958     0.846     0.898       136\n","\n","    accuracy                          0.975      1034\n","   macro avg      0.968     0.920     0.942      1034\n","weighted avg      0.975     0.975     0.974      1034\n","\n"]}],"source":["print(classification_report(y_test, predictions, digits=3))"]},{"cell_type":"markdown","metadata":{"id":"1nffLu6UdnLf"},"source":["Выполним предсказание для конкретного текста"]},{"cell_type":"code","execution_count":199,"metadata":{"id":"prWswDzudnLf"},"outputs":[],"source":["txt = \"As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a å£1500 Bonus Prize, call 09066364589\"\n","txt = preprocess(txt)\n","txt = vectorizer.transform([txt])"]},{"cell_type":"code","execution_count":200,"metadata":{"id":"brfpnzR7dnLf","outputId":"5220b6fe-a3a6-45f4-e726-b3f813ac7751"},"outputs":[{"data":{"text/plain":["array([1], dtype=int64)"]},"execution_count":200,"metadata":{},"output_type":"execute_result"}],"source":["model.predict(txt)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"3_Students.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
