{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *Week 1.*\n",
        "## *Введение в машинное обучение*"
      ],
      "metadata": {
        "id": "iQ1QMK44mqLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1"
      ],
      "metadata": {
        "id": "YMRrHWqpn_CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fPcLIZ1unZwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data-task1.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "X7gY7PUKoBlU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "68d0b756-ed20-4728-bc3a-2e801bc53584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-81f8d39d9b61>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data-task1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data-task1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаляем Орловскую область, Нижегородскую область, Новосибирскую область\n",
        "arr = []\n",
        "arr.append(df.index[df['region_name'] == 'Орловская область'][0])\n",
        "arr.append(df.index[df['region_name'] == 'Нижегородская область'][0])\n",
        "arr.append( df.index[df['region_name'] == 'Новосибирская область'][0])\n",
        "print(arr)\n",
        "df = df.drop(arr, axis = 0)\n",
        "df.reset_index(drop=True, inplace=True) # Смещаем индексы, чтобы шли по порядку\n",
        "df"
      ],
      "metadata": {
        "id": "_19wIbGdoDdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сортируем 'salary' по неубыванию\n",
        "sorted_salary = df['salary'].sort_values()\n",
        "variational_series = pd.DataFrame({'Value': sorted_salary})\n",
        "\n",
        "# Индексы элементов, которые нужно получить\n",
        "indices_to_get = [20, 32, 52]  # Индексы уменьшены на 1, так как нумерация с 0\n",
        "\n",
        "desired_values = variational_series.iloc[indices_to_get]\n",
        "print(desired_values)"
      ],
      "metadata": {
        "id": "_8U6wj8moGlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_value = np.mean(sorted_salary)\n",
        "print(f'Среднее выборочное {mean_value}')\n",
        "median = np.median(sorted_salary)\n",
        "print(f'Выборочная медиана {median}')"
      ],
      "metadata": {
        "id": "--w-VCmRoJgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Week 2.*\n",
        "## *Метод главных компонент*"
      ],
      "metadata": {
        "id": "kK3G0suYmplE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1"
      ],
      "metadata": {
        "id": "YmPIw39ubp54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh9aIXgEadiZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение данных из файла CSV\n",
        "file_path = '13_36.csv'\n",
        "data_ = np.genfromtxt(file_path, delimiter=',')"
      ],
      "metadata": {
        "id": "byxo-2XejR91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=10, svd_solver='full')\n",
        "pca.fit(data_)\n",
        "data = pca.transform(data_)"
      ],
      "metadata": {
        "id": "eft-ONmWqst5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "52b4cb60-3954-4a54-bda7-cb74b0419e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-fb6e192e75b5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_solver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PCA' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coordinate_first_obj_pc1 = data[0, 0]\n",
        "print(f'Координата относительно первой главной компоненты {coordinate_first_obj_pc1}')\n",
        "\n",
        "coordinate_first_obj_pc2 = data[0, 1]\n",
        "print(f'Координата относительно второй главной компоненты {coordinate_first_obj_pc2}')\n",
        "\n",
        "# Доля объясненной дисперсии при использовании первых двух главных компонент\n",
        "explained_variance_ratio_sum = np.sum(pca.explained_variance_ratio_[:2])\n",
        "print(f'Доля объясненной дисперсии {explained_variance_ratio_sum}')"
      ],
      "metadata": {
        "id": "23jX2STTjlqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Минимальное количество главных компонент для доли объясненной дисперсии > 0.85\n",
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "num_components_85 = np.argmax(cumulative_variance > 0.85) + 1\n",
        "print(f'Минимальное количество ГК = {num_components_85}')\n",
        "\n",
        "\n",
        "# График зависимости доли объясненной дисперсии от количества главных компонент\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Количество главных компонент')\n",
        "plt.ylabel('Доля объясненной дисперсии')\n",
        "plt.title('Зависимость доли объясненной дисперсии от количества главных компонент')\n",
        "plt.axvline(x=num_components_85, color='r', linestyle='--', label=f'Количество компоненты для дисперсии > 0.85: {num_components_85}')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8HtKQy8wkaYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_1, z_2 = 0, 0\n",
        "#components = pca.components_\n",
        "plt.scatter(data_[:, 0], data_[:, 1]) #выводит группы\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iF2Ytt79le-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2"
      ],
      "metadata": {
        "id": "XdvSaelUfjQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка матрицы счетов\n",
        "scores = np.loadtxt('scores.csv', delimiter=';')  # Предполагается, что значения разделены пробелами\n",
        "\n",
        "# Загрузка матрицы весов\n",
        "weights = np.loadtxt('weights.csv', delimiter=';')"
      ],
      "metadata": {
        "id": "xP83KvX_fnDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_shape = (100, 100)\n",
        "\n",
        "# Функция для восстановления исходного изображения\n",
        "def reconstruct_image(scores, weights):\n",
        "    reconstructed_image = np.dot(scores, weights.T) # Скалярное произведение двух массивов\n",
        "    return reconstructed_image\n",
        "\n",
        "# Восстановление изображения\n",
        "reconstructed_image = reconstruct_image(scores, weights)\n",
        "\n",
        "# Отображение восстановленного изображения\n",
        "plt.imshow(reconstructed_image.reshape(image_shape), cmap='gray')\n",
        "plt.title('Reconstructed Image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iG1V6XHRhJ09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Week 3.*\n",
        "## *Регрессия*"
      ],
      "metadata": {
        "id": "qM4XyBcTm2r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1"
      ],
      "metadata": {
        "id": "2Epv2fPunu3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "QSw-BCmzoVQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([9, 4, 17, 2, 14, 10, 13, 1, 11, 3])  # Количество людей в очереди\n",
        "y = np.array([15, 9, 41, 1, 32, 22, 30, 4, 31, 8])  # Длительность ожидания в очереди"
      ],
      "metadata": {
        "id": "GlTZSUjfrWpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Рассчитываем средние значения для X и y\n",
        "mean_X = np.mean(X)\n",
        "mean_y = np.mean(y)\n",
        "print(\"Среднее значение X:\", mean_X)\n",
        "print(\"Среднее значение y:\", mean_y)\n"
      ],
      "metadata": {
        "id": "1fsLc5PsvJsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LinearRegression().fit(X.reshape(-1, 1), y)\n",
        "# Получаем коэффициенты модели\n",
        "theta_1 = reg.coef_[0]  # Коэффициент наклона (slope)\n",
        "theta_0 = reg.intercept_  # Пересечение (intercept)\n",
        "\n",
        "print(\"Значение theta_0:\", theta_0)\n",
        "print(\"Значение theta_1:\", theta_1)\n",
        "\n",
        "r_squared = reg.score(X.reshape(-1, 1), y)\n",
        "\n",
        "print(\"R-статистика:\", r_squared)"
      ],
      "metadata": {
        "id": "Q3xL5eBLm_to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2"
      ],
      "metadata": {
        "id": "BZ2qUI6UnxOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqaeN2z8v3qR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*0. Применение полиномиальной регрессии для предсказания непрерывного параметра*"
      ],
      "metadata": {
        "id": "bjyhxYK-eoem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Представленный набор данных — это набор данных о семи различных типах рыб, продаваемых в некоторой рыбной лавке. Наша цель заключается в том, чтобы предсказать массу рыбы по каким-то косвенным признакам, известным о рыбе. Сами признаки, быть может, нужно синтезировать из тех, что известны."
      ],
      "metadata": {
        "id": "VpkXz4mpeygZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При помощи <code>train_test_split()</code> разбейте набор данных на обучающую и тестовую выборки с параметрами, указанными в вашем задании. Используйте стратификацию по колонке <code>Species</code>. Стратификация позволит сохранить доли представленных объектов (по представителям типов рыб) в тренировочной и тестовой выборках."
      ],
      "metadata": {
        "id": "K497OQtR0cbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('fish_train.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "KXoU2OWH0fn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проведем стратифицированное разбиение на обучающую и тестовую выборки\n",
        "X = df.drop('Weight', axis=1)  # Исключаем целевую переменную 'Weight'\n",
        "y = df['Weight']  # Целевая переменная 'Weight'\n",
        "\n",
        "# Разбиение с учетом стратификации по колонке 'Species'\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=df['Species'], random_state=33)\n",
        "\n",
        "# X_train, X_test - матрицы признаков для обучающей и тестовой выборок\n",
        "# y_train, y_test - векторы с целевой переменной для обучающей и тестовой выборок"
      ],
      "metadata": {
        "id": "x9nHMJ7kzqLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вычислите выборочное среднее колонки <code>Width</code> полученной тренировочной выборки."
      ],
      "metadata": {
        "id": "euRpYppY1xuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_width_train = X_train['Width'].mean()\n",
        "print(\"Выборочное среднее колонки 'Width' в тренировочной выборке:\", mean_width_train)"
      ],
      "metadata": {
        "id": "3q_2UVQ_2Avj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*1. Построение базовой модели*\n",
        "\n",
        "Избавьтесь от категориальных признаков и обучите модель линейной регрессии (<code>LinearRegression()</code>) на тренировочном наборе данных. Выполните предсказания для тестового набора данных. Оцените модель при помощи метрики <code>r2_score()</code>."
      ],
      "metadata": {
        "id": "cAQId_950UCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_wo_sp = X_train.drop(['Species'], axis=1)\n",
        "X_test_wo_sp = X_test.drop(['Species'], axis=1)\n",
        "\n",
        "# Обучение модели линейной регрессии\n",
        "model = LinearRegression().fit(X_train_wo_sp, y_train)\n",
        "\n",
        "# Предсказания для тестового набора данных\n",
        "y_pred = model.predict(X_test_wo_sp)\n",
        "\n",
        "# Оценка модели с использованием метрики R2\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R2 score:\", r2)"
      ],
      "metadata": {
        "id": "J9QyfzCx5FrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2. Добавление предварительной обработки признаков.*"
      ],
      "metadata": {
        "id": "qPEFdTMe56b9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Использование PCA**\n",
        "\n",
        "При помощи, например, <code>sns.heatmap()</code>, постройте матрицу корреляций признаков тренировочного набора данных и определите тройку наиболее коррелированных между собой признаков."
      ],
      "metadata": {
        "id": "kKrNXjxTCS1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение матрицы корреляций и нахождение тройки наиболее коррелированных признаков\n",
        "correlation_matrix = X_train.corr()\n",
        "top_correlated_features = correlation_matrix.unstack().sort_values(ascending=False).drop_duplicates()\n",
        "top_correlated_features = top_correlated_features[1:4]  # Берем первые три наиболее коррелированных пары признаков\n",
        "\n",
        "# Визуализация матрицы корреляций\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title('Матрица корреляций признаков')\n",
        "plt.show()\n",
        "\n",
        "# Вывод тройки наиболее коррелированных признаков\n",
        "top_correlated_feature_names = [f\"{pair[0]}, {pair[1]}\" for pair in top_correlated_features.index]\n",
        "result_string = \", \".join(top_correlated_feature_names)\n",
        "print(\"Тройка наиболее коррелированных признаков:\")\n",
        "print(result_string)"
      ],
      "metadata": {
        "id": "HFtdKOdG62hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Линейные модели достаточно плохо реагируют на коррелированные признаки, поэтому от таких признаков имеет смысл избавиться еще до начала обучения."
      ],
      "metadata": {
        "id": "Cx1RHggagRLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для уменьшения количества неинформативных измерений используйте метод главных компонент.\n",
        "\n",
        "1) Примените метод главных компонент (<code>PCA(n_components=3, svd_solver='full')</code>) для трех найденных наиболее коррелированных признаков.\n",
        "\n",
        "2) Вычислите долю объясненной дисперсии при использовании только первой главной компоненты.\n",
        "\n",
        "3) Замените три наиболее коррелированных признака на новый признак <code>Lengths</code>, значения которого совпадают со значениями счетов первой главной компоненты."
      ],
      "metadata": {
        "id": "e6AquRcu7Gvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем метод главных компонент\n",
        "pca = PCA(n_components=3, svd_solver='full')\n",
        "pca_result = pca.fit_transform(X_train[['Length1', 'Length2', 'Length3']])\n",
        "\n",
        "# Вычисляем долю объясненной дисперсии для первой главной компоненты\n",
        "explained_variance_ratio = pca.explained_variance_ratio_[0]\n",
        "\n",
        "# Заменяем три наиболее коррелированных признака на новый признак Lengths\n",
        "X_train['Lengths'] = pca_result[:, 0]\n",
        "X_train.drop(['Length1', 'Length2', 'Length3'], axis=1, inplace=True)\n",
        "\n",
        "# Доля объясненной дисперсии\n",
        "print(\"Доля объясненной дисперсии первой главной компоненты:\", explained_variance_ratio)"
      ],
      "metadata": {
        "id": "VlPLHO2U8PiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Примените полученное преобразование для тех же признаков в тестовом наборе данных. Обратите внимание, что заново обучать преобразование `PCA` не нужно. Аналогично предыдущему этапу замените три рассмотренных признака на один."
      ],
      "metadata": {
        "id": "kDrK2-Nd_ogF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем преобразование PCA к тестовому набору данных\n",
        "pca_result_test = pca.transform(X_test[['Length1', 'Length2', 'Length3']])\n",
        "\n",
        "# Заменяем три наиболее коррелированных признака на новый признак Lengths в тестовом наборе\n",
        "X_test['Lengths'] = pca_result_test[:, 0]\n",
        "X_test.drop(['Length1', 'Length2', 'Length3'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "xEOAkMFf-T5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучите базовую модель линейной регрессии на полученных тренировочных данных, снова выбросив категориальные признаки. Выполните предсказания для тестовых данных, оцените при помощи <code>r2_score()</code>."
      ],
      "metadata": {
        "id": "NGiPC64DAmRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_wo_sp = X_train.drop(['Species'], axis=1)\n",
        "X_test_wo_sp = X_test.drop(['Species'], axis=1)\n",
        "\n",
        "# Обучение модели линейной регрессии на обновленных данных\n",
        "model_updated = LinearRegression().fit(X_train_wo_sp, y_train)\n",
        "\n",
        "# Предсказания для тестового набора данных\n",
        "y_pred_updated = model_updated.predict(X_test_wo_sp)\n",
        "\n",
        "# Оценка модели с использованием метрики R2\n",
        "r2_updated = r2_score(y_test, y_pred_updated)\n",
        "print(\"R2 score на обновленных данных:\", r2_updated)"
      ],
      "metadata": {
        "id": "EVu8wL6QA1Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что точность значительно не изменилась."
      ],
      "metadata": {
        "id": "BFPWkxOnieem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Модификация признаков**"
      ],
      "metadata": {
        "id": "hJm3yq--BcT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Постройте графики зависимостей признаков от целевой переменной, например, при помощи <code>sns.pairplot()</code>."
      ],
      "metadata": {
        "id": "T11p0ltmEFwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Объединим признаки и целевую переменную в один DataFrame\n",
        "train_data = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# Построим матрицу графиков рассеяния\n",
        "sns.pairplot(train_data, vars=['Lengths', 'Height', 'Width', 'Weight'], kind='scatter')\n",
        "plt.suptitle('Зависимости признаков от целевой переменной', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0rifKCoWEQYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что масса, вообще говоря, нелинейно зависит от остальных параметров. Значит, чтобы линейная модель хорошо справлялась с предсказанием, признаки имеет смысл преобразовать так, чтобы зависимость стала более похожей на линейную. Но как придумать такую зависимость?"
      ],
      "metadata": {
        "id": "L-v73i1vhi_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Логично предположить, что масса рыбы должна каким-то гладким образом зависеть от остальных параметров, отвечающих так или иначе за размеры. Если вспомнить, что масса — это произведение плотности на объем, то\n",
        "\n",
        "$$\n",
        "m = \\rho \\cdot V.\n",
        "$$\n",
        "\n",
        "Допустим, что средняя плотность у всех рыб одинаковая, и вспомним, что при гомотетии объем объекта зависит от линейных размеров как куб, тогда получим\n",
        "\n",
        "$$\n",
        "m\\sim V\\sim d^3\n",
        "$$\n",
        "\n",
        "Все признаки тренировочного и тестового наборов данных, отвечающие так или иначе за размеры (<code>Height, Width, Lengths</code>), возведите в третью степень, и проверьте, стала ли зависимость массы от этих признаков похожа на линейную."
      ],
      "metadata": {
        "id": "sSIndS-yCP6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Возведение признаков в третью степень\n",
        "X_train_cubed = X_train[['Height', 'Width', 'Lengths']].apply(lambda x: x ** 3)\n",
        "X_test_cubed = X_test[['Height', 'Width', 'Lengths']].apply(lambda x: x ** 3)\n",
        "\n",
        "# Объединим возведенные в степень признаки с остальными признаками\n",
        "X_train_cubed = pd.concat([X_train.drop(['Height', 'Width', 'Lengths'], axis=1), X_train_cubed], axis=1)\n",
        "X_test_cubed = pd.concat([X_test.drop(['Height', 'Width', 'Lengths'], axis=1), X_test_cubed], axis=1)\n",
        "\n",
        "# Объединим признаки и целевую переменную в один DataFrame\n",
        "train_data_cubed = pd.concat([X_train_cubed, y_train], axis=1)\n",
        "\n",
        "# Построим матрицу графиков рассеяния\n",
        "sns.pairplot(train_data_cubed, vars=['Height', 'Width', 'Lengths', 'Weight'], kind='scatter')\n",
        "plt.suptitle('Зависимости признаков (в третьей степени) от целевой переменной', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DOK0OyLVEmrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Введите выборочное среднее колонки <code>Width</code> тренировочного набора данных после возведения в куб."
      ],
      "metadata": {
        "id": "Jm-1XAOpE_Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вычисление выборочного среднего для колонки 'Width' после возведения в куб\n",
        "mean_width_cubed_train = X_train_cubed['Width'].mean()\n",
        "print(\"Выборочное среднее колонки 'Width' после возведения в куб:\", mean_width_cubed_train)"
      ],
      "metadata": {
        "id": "5-2zYkgWGCFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выберите изображения, соответствующие зависимости <code>Weight</code> от <code>Width</code> до преобразования и после."
      ],
      "metadata": {
        "id": "PCKM-CcQjfH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучите базовую модель линейной регресси на полученных тренировочных данных, снова выбросив категориальные признаки. Выполните предсказания для тестовых данных, оцените при помощи `r2_score()`."
      ],
      "metadata": {
        "id": "NZtrdFamiTl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Убираем категориальные признаки из данных\n",
        "X_train_cubed_wo_sp = X_train_cubed.drop(['Species'], axis=1)\n",
        "X_test_cubed_wo_sp = X_test_cubed.drop(['Species'], axis=1)\n",
        "\n",
        "# Обучение модели линейной регрессии на числовых данных с признаками, возведенными в третью степень\n",
        "model_cubed = LinearRegression().fit(X_train_cubed_wo_sp, y_train)\n",
        "\n",
        "# Предсказания для тестового набора данных\n",
        "y_pred_cubed = model_cubed.predict(X_test_cubed_wo_sp)\n",
        "\n",
        "# Оценка модели с использованием метрики R2\n",
        "r2_cubed = r2_score(y_test, y_pred_cubed)\n",
        "print(\"R2 score для базовой модели с признаками, возведенными в куб:\", r2_cubed)"
      ],
      "metadata": {
        "id": "ybKUGN-GGUoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание на то, как такая нехитрая работа с признаками помогла разительно улучшить точность модели!"
      ],
      "metadata": {
        "id": "WReH7dKZirOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Добавление категориальных признаков**"
      ],
      "metadata": {
        "id": "MesFzgX1Sqgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Произведите <code>one-hot</code> кодировние категориального признака `Species`, например, с помощью <code>pd.get_dummies()</code>.\n",
        "\n",
        "Обучите модель линейной регресси на полученных тренировочных данных. Выполните предсказания для тестовых данных, оцените модель при помощи <code>r2_score()</code>.\n",
        "\n",
        "<b>Примечание</b>: Мы специально использовали стратифицированное разделение, чтобы все значения категориального признака <code>Species</code> присутствовали во всех наборах данных. Но такое возможно не всегда. Про то, как с этим бороться можно почитать, [например, здесь](https://predictivehacks.com/?all-tips=how-to-deal-with-get_dummies-in-train-and-test-dataset)."
      ],
      "metadata": {
        "id": "VThVRIkvSuV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем One-Hot Encoding к категориальному признаку 'Species'\n",
        "X_train_cubed_encoded = pd.get_dummies(X_train_cubed, columns=['Species'])\n",
        "X_test_cubed_encoded = pd.get_dummies(X_test_cubed, columns=['Species'])\n",
        "\n",
        "# Обучение модели линейной регрессии на обновленных данных с One-Hot Encoding\n",
        "model_cubed_encoded = LinearRegression().fit(X_train_cubed_encoded, y_train)\n",
        "\n",
        "# Предсказания для тестового набора данных\n",
        "y_pred_cubed_encoded = model_cubed_encoded.predict(X_test_cubed_encoded)\n",
        "\n",
        "# Оценка модели с использованием метрики R2\n",
        "r2_encoded = r2_score(y_test, y_pred_cubed_encoded)\n",
        "print(\"R2 score для модели с One-Hot Encoding:\", r2_encoded)"
      ],
      "metadata": {
        "id": "AcJDFGFLSpzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "И снова точность возрасла."
      ],
      "metadata": {
        "id": "bBDsQEGvjMV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как можно увидеть, после `one-hot` кодирования признаки стали коррелированы. От этого можно избавиться, например, при помощи параметра `drop_first=True`. Заново обучите модель после исправления этого недочета. Выполните предсказания для тестовых данных, оцените модель при помощи <code>r2_score()</code>."
      ],
      "metadata": {
        "id": "vciWw1gajo5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем One-Hot Encoding к категориальному признаку 'Species'\n",
        "X_train_drop_first = pd.get_dummies(X_train_cubed, drop_first=True)\n",
        "X_test_drop_first = pd.get_dummies(X_test_cubed, drop_first=True)\n",
        "\n",
        "# Обучение модели линейной регрессии на обновленных данных с One-Hot Encoding\n",
        "model_drop_first = LinearRegression().fit(X_train_drop_first, y_train)\n",
        "\n",
        "# Предсказания для тестового набора данных\n",
        "y_pred_drop_first = model_drop_first.predict(X_test_drop_first)\n",
        "\n",
        "# Оценка модели с использованием метрики R2\n",
        "r2_drop_first = r2_score(y_test, y_pred_drop_first)\n",
        "print(\"R2 score для модели с One-Hot Encoding:\", r2_drop_first)"
      ],
      "metadata": {
        "id": "zV6u-Ha1kH3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "На таком сравнительно небольшом наборе данных, впрочем, разницы мы не видим."
      ],
      "metadata": {
        "id": "ABS2Tw6tkSW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3"
      ],
      "metadata": {
        "id": "yL24gj4OnzEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "jzs_J11Qn0kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('fish_train.csv')\n",
        "df_pred = pd.read_csv('fish_reserved.csv')"
      ],
      "metadata": {
        "id": "iYLmHxb5J2uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на признаки (X) и целевую переменную (y)\n",
        "X_train = df_train.drop('Weight', axis=1)\n",
        "y_train = df_train['Weight']\n",
        "X_test = df_pred  # Признаки для тестового набора"
      ],
      "metadata": {
        "id": "zShluS9wSkOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Метод 1**\n",
        "\n",
        "Без МГК + ширина, высота и все длины отдельно в кубы + dummies"
      ],
      "metadata": {
        "id": "CawsGQBrdCUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Возведение признаков в третью степень\n",
        "X_train_cubed_1 = X_train[['Height', 'Width', 'Length1', 'Length2', 'Length3']].apply(lambda x: x ** 3)\n",
        "X_test_cubed_1= X_test[['Height', 'Width', 'Length1', 'Length2', 'Length3']].apply(lambda x: x ** 3)\n",
        "\n",
        "# Объединим возведенные в степень признаки с остальными признаками\n",
        "X_train_cubed_1 = pd.concat([X_train.drop(['Height', 'Width', 'Length1', 'Length2', 'Length3'], axis=1), X_train_cubed_1], axis=1)\n",
        "X_test_cubed_1 = pd.concat([X_test.drop(['Height', 'Width', 'Length1', 'Length2', 'Length3'], axis=1), X_test_cubed_1], axis=1)\n",
        "\n",
        "# Объединим признаки и целевую переменную в один DataFrame\n",
        "train_data_cubed_1 = pd.concat([X_train_cubed_1, y_train], axis=1)"
      ],
      "metadata": {
        "id": "K2Zq8Nz5c_4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded_1 = pd.get_dummies(X_train_cubed_1, columns=['Species'], drop_first=True)\n",
        "X_test_encoded_1 = pd.get_dummies(X_test_cubed_1, columns=['Species'], drop_first=True)\n",
        "\n",
        "# Обучение модели линейной регрессии на числовых данных с признаками, возведенными в третью степень\n",
        "model_1 = LinearRegression().fit(X_train_encoded_1, y_train)\n",
        "\n",
        "# Предсказания для тестового набора данных\n",
        "y_pred_1 = model_1.predict(X_test_encoded_1)\n",
        "\n",
        "# Округляем предсказания до 5 знаков после запятой\n",
        "y_pred_rounded_1 = [round(pred, 5) for pred in y_pred_1]\n",
        "\n",
        "# Вывод предсказаний в виде списка с округлением\n",
        "print(\"Предсказания:\", y_pred_rounded_1)\n",
        "# 0.979124974443"
      ],
      "metadata": {
        "id": "8NVtgkAadck7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Метод 2**\n",
        "\n",
        "PCA(length 1, 2, 3) + кубы + get_dummies"
      ],
      "metadata": {
        "id": "dHUEvJ-9eCli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем метод главных компонент\n",
        "pca = PCA(n_components=3, svd_solver='full')\n",
        "pca_result = pca.fit_transform(X_train[['Length1', 'Length2', 'Length3']])\n",
        "\n",
        "# Заменяем три наиболее коррелированных признака на новый признак Lengths\n",
        "X_train['Lengths'] = pca_result[:, 0]\n",
        "X_train.drop(['Length1', 'Length2', 'Length3'], axis=1, inplace=True)\n",
        "\n",
        "# Применяем преобразование PCA к тестовому набору данных\n",
        "pca_result_test = pca.transform(X_test[['Length1', 'Length2', 'Length3']])\n",
        "\n",
        "# Заменяем три наиболее коррелированных признака на новый признак Lengths в тестовом наборе\n",
        "X_test['Lengths'] = pca_result_test[:, 0]\n",
        "X_test.drop(['Length1', 'Length2', 'Length3'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "CS9-qLM7UosW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Возведение признаков в третью степень\n",
        "X_train_cubed_2 = X_train[['Height', 'Width', 'Lengths']].apply(lambda x: x ** 3)\n",
        "X_test_cubed_2 = X_test[['Height', 'Width', 'Lengths']].apply(lambda x: x ** 3)\n",
        "\n",
        "# Объединим возведенные в степень признаки с остальными признаками\n",
        "X_train_cubed_2 = pd.concat([X_train.drop(['Height', 'Width', 'Lengths'], axis=1), X_train_cubed_2], axis=1)\n",
        "X_test_cubed_2 = pd.concat([X_test.drop(['Height', 'Width', 'Lengths'], axis=1), X_test_cubed_2], axis=1)\n"
      ],
      "metadata": {
        "id": "Dl9NGKlgU-gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded_2 = pd.get_dummies(X_train_cubed_2, columns=['Species'], drop_first=True)\n",
        "X_test_encoded_2 = pd.get_dummies(X_test_cubed_2, columns=['Species'], drop_first=True)\n",
        "\n",
        "# Обучение модели линейной регрессии на числовых данных с признаками, возведенными в третью степень\n",
        "model_2 = LinearRegression().fit(X_train_encoded_2, y_train)\n",
        "\n",
        "# Предсказания для тестового набора данных\n",
        "y_pred_2 = model_2.predict(X_test_encoded_2)\n",
        "\n",
        "# Округляем предсказания до 5 знаков после запятой\n",
        "y_pred_rounded_2 = [round(pred, 5) for pred in y_pred_2]\n",
        "\n",
        "# Вывод предсказаний в виде списка с округлением\n",
        "print(\"Предсказания (в виде списка с округлением):\", y_pred_rounded_2)\n",
        "\n",
        "# 0.958"
      ],
      "metadata": {
        "id": "WflZkXkDVFaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шайтанамана**"
      ],
      "metadata": {
        "id": "5i5N8VOOeox-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = y_pred_1\n",
        "m2 = y_pred_2\n",
        "\n",
        "dif = []\n",
        "for i in range(40):\n",
        "    # print(m2[i],\" | \", m1[i],\" | \", m2[i]-m1[i],\" | \", (m2[i]-m1[i])/43)\n",
        "    a = m1[i] - ((m1[i]-m1[i])/4) # с этим числом поиграйся (лучший результат у меня был при делении на 3)\n",
        "    dif.append(a)\n",
        "\n",
        "print(dif)\n",
        "# 1 - 0.976069716444 X\n",
        "# 2 - 0.980592924359\n",
        "# 3 - 0.980769292 Max\n",
        "# 4 - 0.980607844258\n",
        "# 5 - 0.980431093513\n",
        "# 6 - 0.980279975475\n",
        "# 7 - 0.98015573155"
      ],
      "metadata": {
        "id": "HNbN5K8EeoL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Week 4.*\n",
        "\n",
        "Классификаторы k-NN и наивный Байес"
      ],
      "metadata": {
        "id": "LpmF-gFa169w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задания после видео"
      ],
      "metadata": {
        "id": "faCuQPua2LMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "fWHqWktd2s16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(1, 28, 10, 1),\n",
        "        (2, 49, 49, 1),\n",
        "        (3, 48, 35, 0),\n",
        "        (4, 36, 33, 1),\n",
        "        (5, 45, 54, 0)]\n",
        "obj = (33, 47)"
      ],
      "metadata": {
        "id": "e2fWk0Y12Poa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "euclid = []\n",
        "for d in data:\n",
        "  t = math.sqrt((d[1]-obj[0])**2 +(d[2]-obj[1])**2)\n",
        "  euclid.append((d[0], t))\n",
        "euclid"
      ],
      "metadata": {
        "id": "ax2R1LpG20Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manhattan = []\n",
        "for d in data:\n",
        "  t = abs(d[1]-obj[0]) + abs(d[2]-obj[1])\n",
        "  manhattan.append((d[0], t))\n",
        "manhattan"
      ],
      "metadata": {
        "id": "vR3tz44P4Av-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cheb = []\n",
        "for d in data:\n",
        "  t = max(abs(d[1]-obj[0]), abs(d[2]-obj[1]))\n",
        "  cheb.append((d[0], t))\n",
        "cheb"
      ],
      "metadata": {
        "id": "Gn3VgGW24gsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# взвешанный k-NN\n",
        "euclid = []\n",
        "for d in data:\n",
        "  t = math.sqrt((d[1]-obj[0])**2 +(d[2]-obj[1])**2)\n",
        "  w = 1/((d[1]-obj[0])**2 +(d[2]-obj[1])**2)\n",
        "  euclid.append((d[0], t, d[3], w))\n",
        "print(euclid)\n",
        "\n",
        "w0, w1 = 0, 0\n",
        "for e in euclid:\n",
        "  if e[2] == 0:\n",
        "    w0 += e[3]\n",
        "  else:\n",
        "    w1 += e[3]\n",
        "\n",
        "print(w0, w1)"
      ],
      "metadata": {
        "id": "eJS1h-aDCWCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "letter =  70\n",
        "prize_raw = 5\n",
        "prize_spam = 6\n",
        "spam = 24\n",
        "raw = 25\n",
        "\n",
        "p_prize_spam = prize_spam / (spam + prize_spam)\n",
        "print(p_prize_spam)\n",
        "\n",
        "p_spam_prize = p_prize_spam * ((spam + prize_spam)/letter) / ((prize_raw + prize_spam)/ letter)\n",
        "print(p_spam_prize)"
      ],
      "metadata": {
        "id": "L6p1s2ecR8mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "spam = 11\n",
        "raw = 26\n",
        "spam_words = 69\n",
        "raw_words = 48\n",
        "\n",
        "p_spam = spam / (spam + raw)\n",
        "print(p_spam)\n",
        "\n",
        "ln_p_spam = math.log(p_spam)\n",
        "print(ln_p_spam)"
      ],
      "metadata": {
        "id": "Ze5gVp3ZW9IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "win, million, ruble, again = 6, 10, 5, 7\n",
        "drops, ways, get, rich = 3, 9, 14, 15\n",
        "V = 8\n",
        "r = 1\n",
        "all = win + million + ruble + again + drops + ways + get + rich\n",
        "print(all)\n",
        "\n",
        "win_spam = (win + 1) / (V + all + r)\n",
        "million_spam = (million + 1) / (V + all + r)\n",
        "dollars_spam = (0 + 1)/ (V + all + r)\n",
        "F_spam = ln_p_spam + math.log(win_spam)+ math.log(million_spam)+ math.log(dollars_spam)\n",
        "print(f'F = {F_spam}')\n",
        "\n",
        "all_not = 3 + 5 + 10 + 2 + 7 + 13 + 5 + 3\n",
        "ln_p_not_spam = math.log(raw / (spam + raw))\n",
        "win_not_spam = (3 + 1) / (V + all_not + r)\n",
        "million_not_spam = (5 + 1) / (V + all_not + r)\n",
        "dollars_not_spam = (0 + 1)/ (V + all_not + r)\n",
        "\n",
        "F_not_spam = ln_p_not_spam + math.log(win_not_spam)+ math.log(million_not_spam)+ math.log(dollars_not_spam)\n",
        "print(f'F = {F_not_spam}')\n",
        "\n",
        "p_spam = 1/ (1 + math.exp(F_not_spam - F_spam))\n",
        "print(p_spam)\n"
      ],
      "metadata": {
        "id": "keC4SBr5YhIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1"
      ],
      "metadata": {
        "id": "hSkcBNMkPZvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import euclidean_distances\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "kO-DFkZnP40Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "Igj8_8QdPhyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Координаты нового объекта\n",
        "new_object = (54, 68)\n",
        "\n",
        "# Вычисление расстояния до ближайшего соседа и его идентификатора\n",
        "min_distance = float('inf')  # Инициализация переменной с бесконечностью\n",
        "nearest_neighbor_id = None\n",
        "\n",
        "# Словарь для хранения расстояний до ближайших точек\n",
        "distances = {}\n",
        "\n",
        "# Вычисление расстояний до каждой точки\n",
        "# Вычисление расстояний до каждой точки\n",
        "for index, row in data.iterrows():\n",
        "    x = row['X']\n",
        "    y = row['Y']\n",
        "    distance = math.sqrt((x - new_object[0])**2 + (y - new_object[1])**2)\n",
        "    distances[row['id']] = distance\n",
        "\n",
        "    if distance < min_distance:\n",
        "        min_distance = distance\n",
        "        nearest_neighbor_id = row['id']\n",
        "\n",
        "# Находим три ближайших точки\n",
        "nearest_neighbors = sorted(distances, key=distances.get)[:3]\n",
        "\n",
        "print('Расстояние до ближайшего соседа:', min_distance)\n",
        "print('Идентификаторы трех ближайших точек к (54, 68):', nearest_neighbors)\n",
        "\n",
        "# Получаем классы ближайших соседей\n",
        "nearest_neighbors_classes = [data[data['id'] == neighbor_id]['Class'].values[0] for neighbor_id in nearest_neighbors]\n",
        "\n",
        "# Подсчет частоты каждого класса среди ближайших соседей\n",
        "class_counter = Counter(nearest_neighbors_classes)\n",
        "\n",
        "# Находим класс с наибольшей частотой\n",
        "most_common_class = class_counter.most_common(1)[0][0]\n",
        "\n",
        "print('Класс нового объекта:', most_common_class)"
      ],
      "metadata": {
        "id": "O3hWvsC7Rutl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вычисление расстояния до ближайшего соседа\n",
        "min_manhattan_distance = float('inf')  # Инициализация переменной с бесконечностью\n",
        "\n",
        "# Словарь для хранения расстояний до ближайших точек\n",
        "manhattan_distances = {}\n",
        "\n",
        "# Вычисление расстояний до каждой точки с использованием манхэттенского расстояния\n",
        "for index, row in data.iterrows():\n",
        "    x = row['X']\n",
        "    y = row['Y']\n",
        "    manhattan_distance = abs(x - new_object[0]) + abs(y - new_object[1])\n",
        "    manhattan_distances[row['id']] = manhattan_distance\n",
        "\n",
        "    if manhattan_distance < min_manhattan_distance:\n",
        "        min_manhattan_distance = manhattan_distance\n",
        "\n",
        "# Находим три ближайших точки\n",
        "nearest_neighbors_manhattan = sorted(manhattan_distances, key=manhattan_distances.get)[:3]\n",
        "\n",
        "print('Манхэттенское расстояние до ближайшего соседа:', min_manhattan_distance)\n",
        "print('Идентификаторы трех ближайших точек к (54, 68) с использованием манхэттенского расстояния:', nearest_neighbors_manhattan)\n",
        "\n",
        "# Получаем классы ближайших соседей\n",
        "nearest_neighbors_classes = [data[data['id'] == neighbor_id]['Class'].values[0] for neighbor_id in nearest_neighbors_manhattan]\n",
        "\n",
        "# Определение класса нового объекта на основе наиболее частого класса среди ближайших соседей\n",
        "class_counter = Counter(nearest_neighbors_classes)\n",
        "most_common_class = class_counter.most_common(1)[0][0]\n",
        "\n",
        "print('Класс нового объекта:', most_common_class)"
      ],
      "metadata": {
        "id": "_5m8QKcSAMoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2"
      ],
      "metadata": {
        "id": "EkquCxP4wZXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0. Применение метода KNN для решения задачи классификации**"
      ],
      "metadata": {
        "id": "udpKd3_7yU4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Набор данных получен в результате переписи населения 1994 года и содержит информацию о некотором количестве людей, проживающих в США. Задача состоит в том, чтобы предсказать, зарабатывает человек более $50к в год или нет. Список признаков:\n",
        "\n",
        "*   <b>age</b>: возраст человека.\n",
        "*   <b>workclass</b>: статус занятости.\n",
        "*   <b>fnlwgt</b>: количество людей, которое, по мнению переписи, представляет запись.\n",
        "*   <b>education</b>: высший уровень образования, достигнутый человеком.\n",
        "*   <b>education-num</b>: высший уровень образования, достигнутый человеком в числовой форме.\n",
        "*   <b>marital-status</b>: семейное положение человека.\n",
        "*   <b>occupation</b>: общий род занятий человека.\n",
        "*   <b>relationship</b>: представляет то, чем этот человек является по отношению к другим (перекликается с признаком <b>marital-status</b>).\n",
        "*   <b>race</b>: раса.\n",
        "*   <b>sex</b>: пол.\n",
        "*   <b>capital-gain</b>: прирост капитала.\n",
        "*   <b>capital-loss</b>: убыток капитала.\n",
        "*   <b>hours-per-week</b>: число рабочих часов в неделю.\n",
        "*   <b>native-country</b>: страна происхождения.\n",
        "*   <b>the label</b>: отклик -- зарабатывает больше $50к или меньше.\n",
        "\n"
      ],
      "metadata": {
        "id": "cZnGWUYq7X3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Немного про метрики качества модели**"
      ],
      "metadata": {
        "id": "40XSwwjlypYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для начала рассмотрим так называемую матрицу ошибок (confusion matrix)\n",
        "-- способ разделить объекты на $4$ группы в зависимости от комбинации\n",
        "истинного класса и ответа классификатора:\n",
        "\n",
        "-   TP (True Positives) -- верно классифицированные объекты, исходно     относящиеся к классу \"$+1$\";\n",
        "\n",
        "-   TN (True Negatives) -- верно классифицированные объекты, исходно     относящиеся к классу \"$-1$\";\n",
        "\n",
        "-   FN (False Negatives) -- неверно классифицированные объекты, исходно     относящиеся к классу \"$+1$\" (ошибка I рода);\n",
        "\n",
        "-   FP (False Positives) -- неверно классифицированные объекты, исходно     относящиеся к классу \"$-1$\" (ошибка II рода).\n",
        "\n",
        "Обычно, конечно, оперируют не абсолютными показателями, а относительными\n",
        "-- долями (rates), находящимися в диапазоне от $0$ до $1$:\n",
        "\n",
        "-   доля правильных ответов классификатора (иногда -- точность): $$\\mathsf{Accuracy} = \\frac{TP + TN}{TP + FP + FN + TN}.$$ Эта величина показывает отношение количества верно классифицированных объектов к общему количеству классифицируемых объектов и, грубо говоря, оценивает вероятность случайному объекту быть правильно классифицированным.\n",
        "\n",
        "-   доля истинно положительных примеров -- True Positives Rate (TPR) или     Sensitivity (чувствительность) или Recall: $$\\mathsf{T P R}=\\frac{T P}{T P+F N}.$$ Эта величина показывает отношение количества верно классифицированных объектов, относящихся к классу \"$+1$\", к общему количеству объектов класса \"$+1$\". Иными словами -- это оценка вероятности, что объект, относящийся к классу \"$+1$\" будет классифицирован корректно.\n",
        "\n",
        "-   доля ложно положительных примеров обозначается как -- False Positives Rate (FPR): $$\\mathsf{F P R}=\\frac{F P}{FP + TN}.$$ Величина показывает отношение количества неверно классифицированных объектов, относящихся к классу \"$-1$\", к общему количеству объектов класса \"$-1$\", или оценивает вероятность, что объект, относящийся к классу \"$-1$\", будет классифицирован неверно.\n",
        "\n",
        "-   Специфичность (Specificity) или True Negatives Rate (TNR): $$\\mathsf{TNR} = 1 - \\mathsf{F P R} =\\frac{T N}{T N+F P}.$$ Величина показывает отношение количества верно классифицированных объектов, относящихся к классу \"$-1$\", к общему количеству объектов класса \"$-1$\", или оценивает вероятность, что объект, относящийся к классу \"$-1$\", будет классифицирован верно.\n",
        "\n",
        "-   Precision (точность): $$\\mathsf{Precision} =\\frac{TP}{TP + FP}.$$ Величина показывает, какая доля объектов, отнесенных классификатором к классу \"$+1$\", действительно относится к этому классу.\n",
        "\n",
        "Естественно возникает вопрос, нет ли какого-то обобщающего критерия,\n",
        "который может характеризовать качество построенной модели. Один из них --\n",
        "так называемая $F$-мера ($F_1$-мера, $F$ score, $F_1$ score)\n",
        "определяется следующим соотношением:\n",
        "$$F = F_1 = 2 \\cdot \\frac{\\mathsf{Precision} \\cdot \\mathsf{Recall}}{\\mathsf{Precision} + \\mathsf{Recall}}.$$\n",
        "\n",
        "**Замечание**. *$F$-мера является средним гармоническим величин\n",
        "$\\mathsf{Precision}$ и $\\mathsf{Recall}$ и заключена в диапазоне\n",
        "$[0, 1]$. Среднее гармоническое обладает важным свойством: оно близко к\n",
        "нулю, если хотя бы один из аргументов близок к нулю. Поэтому оно является\n",
        "куда более предпочтительным, чем, скажем, среднее арифметическое: если\n",
        "алгоритм относит все объекты к положительному классу, то\n",
        "$\\mathsf{Recall}= 1$, а $\\mathsf{Precision}$, скорее всего, будет\n",
        "небольшим. Но тогда среднее арифметическое будет больше, чем $0.5$, что,\n",
        "конечно, никуда не годится.*"
      ],
      "metadata": {
        "id": "NwNdoJiD9h1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Импорт библиотек**"
      ],
      "metadata": {
        "id": "39NKRkqjywcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "xNfIA65LCH84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считайте набор данных в датафрейм. Исходя из описания признаков можно сразу избавиться от признаков <code>education</code> и <code>marital-status</code>. Удалите соответствующие колонки из набора данных."
      ],
      "metadata": {
        "id": "_G1PuXfscIZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"adult_data_train.csv\")\n",
        "# Удаляем колонки 'education' и 'marital-status'\n",
        "data = data.drop(['education', 'marital-status'], axis=1)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "8ex5DndtAOnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определите количество числовых и нечисловых признаков."
      ],
      "metadata": {
        "id": "accrQdXa_pbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "info = data.info()\n",
        "\n",
        "numeric_features_count = data.select_dtypes(include=['number']).shape[1]\n",
        "non_numeric_features_count = data.select_dtypes(exclude=['number']).shape[1]\n",
        "\n",
        "print(\"Количество числовых признаков:\", numeric_features_count)\n",
        "print(\"Количество нечисловых признаков:\", non_numeric_features_count)"
      ],
      "metadata": {
        "id": "NF67lPph_xBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Постройте гистограмму распределения объектов по классам. Вычислите долю объектов класса $0$."
      ],
      "metadata": {
        "id": "EcE85lviBatz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(data['label'], bins=2, edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Класс')\n",
        "plt.ylabel('Количество объектов')\n",
        "plt.xticks([0, 1], ['<=50K', '>50K'])\n",
        "plt.title('Гистограмма распределения объектов по классам')\n",
        "plt.show()\n",
        "\n",
        "# Вычисление доли объектов класса 0\n",
        "class_0_count = (data['label'] == 0).sum()\n",
        "total_samples = len(data)\n",
        "class_0_fraction = class_0_count / total_samples\n",
        "\n",
        "print(\"Доля объектов класса 0:\", class_0_fraction)"
      ],
      "metadata": {
        "id": "gujxc3m2BtVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Построение базовой модели**\n",
        "\n",
        "В качестве первого приближения имеет смысл построить модель классификации, опираясь исключительно на числовые признаки.\n",
        "\n",
        "Отберите из набора данных только числовые признаки. При помощи <code>train_test_split()</code> разбейте набор данных на обучающую и тестовую выборки <b>с параметрами, указанными в вашем задании</b>. Используйте стратификацию по колонке <code>label</code>.\n",
        "\n",
        "Вычислите выборочное среднее колонки <code>fnlwgt</code> тренировочного набора данных.\n",
        "\n",
        "Обучите модель <code>KNeighborsClassifier()</code> с параметрами по умолчанию на тренировочных данных.\n",
        "\n",
        "Как видно из предыдущего пункта, в наборе данных наблюдается явный дисбаланс представителей классов. Это следует учесть при оценке модели. Вычислите <code>f1_score</code> модели на тестовых данных (рекомендуем использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\">соответствующую функцию</a> с параметрами по умолчанию.\n",
        "\n",
        "В качестве альтернативы можно использовать так называемый <a href = \"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\"><code>classification_report()</code></a>, где приведены сразу несколько метрик (не стоит забывать про параметр <code>digits</code>)."
      ],
      "metadata": {
        "id": "owFlxSBa_XfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = data.select_dtypes(include=['number'])\n",
        "\n",
        "# Разбиваем на обучающую и тестовую выборки с учетом стратификации\n",
        "X = numeric_features.drop('label', axis=1)\n",
        "y = numeric_features['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)\n",
        "\n",
        "mean_fnlwgt_train = X_train['fnlwgt'].mean()\n",
        "print(\"Выборочное среднее колонки 'fnlwgt' в тренировочном наборе данных:\", mean_fnlwgt_train)"
      ],
      "metadata": {
        "id": "jdhQDnYNGlSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"F1 score:\", f1)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n"
      ],
      "metadata": {
        "id": "SeV9t4e6UTwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стоит помнить, что KNN является метрическим классификатором, поэтому значения признаков перед обучением модели следует нормировать.\n",
        "\n",
        "Обучите преобразование <code>MinMaxScaler()</code> на тренировочном наборе данных и примените его для тренировочных и тестовых данных.\n",
        "\n",
        "Вычислите выборочное среднее колонки <code>fnlwgt</code> тренировочного набора данных после нормировки.\n",
        "\n",
        "Заново обучите и оцените модель на преобразованных данных. Вычислите <code>f1_score()</code> модели."
      ],
      "metadata": {
        "id": "Q3yYPF5CFD0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "mean_fnlwgt_train_scaled = X_train_scaled[:, X.columns.get_loc('fnlwgt')].mean()\n",
        "print(\"Выборочное среднее колонки 'fnlwgt' в тренировочном наборе данных после нормировки:\", mean_fnlwgt_train_scaled)"
      ],
      "metadata": {
        "id": "2jC-5-dhBAij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_scaled = KNeighborsClassifier()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "\n",
        "f1_scaled = f1_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(\"F1 score на нормализованных данных:\", f1_scaled)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_scaled, digits=4))"
      ],
      "metadata": {
        "id": "zZzj4PCnU3L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что после линейной нормировки качество выросло.\n",
        "\n",
        "<b>Важно: </b>На дальнейших этапах подразумевается использование линейной нормировки непосредственно перед обучением без дополнительных напоминаний."
      ],
      "metadata": {
        "id": "FXNb8sWVHlQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Работа с нечисловыми признаками**"
      ],
      "metadata": {
        "id": "e_kLHKu2B9lZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Визуализация***\n",
        "\n",
        "Для дальнейшего улучшения качества модели имеет смысл задействовать нечисловые признаки исходного датасета (без колонок <code>education</code> и <code>marital-status</code>).\n",
        "\n",
        "Постройте гистограммы, иллюстрирующие частоту того или иного значения по каждому нечисловому признаку, например, при помощи <code>sns.barplot()</code>."
      ],
      "metadata": {
        "id": "VFVVV6TJL1YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_numeric_features = data.select_dtypes(exclude=['number'])\n",
        "\n",
        "for feature in non_numeric_features:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(x=feature, data=data)\n",
        "    plt.title(f'Гистограмма для {feature}')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XEkIN_UBDeAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Удаление пропущенных значений***\n",
        "\n",
        "Определите число строк исходного набора данных (без колонок <code>education</code> и <code>marital-status</code>), в которых присутствует хотя бы одно пропущенное значение."
      ],
      "metadata": {
        "id": "TlJGKMfqF5RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy = data.copy()\n",
        "df_copy.replace('?', pd.NA, inplace=True)\n",
        "\n",
        "rows_with_missing_values = df_copy.isnull().any(axis=1).sum()\n",
        "\n",
        "print(\"Число строк с хотя бы одним пропущенным значением:\", rows_with_missing_values)\n",
        "df_copy"
      ],
      "metadata": {
        "id": "Pyur9pDvHFoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что в датасете содержится менее 10% строк, содержащих пропуски. Выкидывать такое количество строк — не очень хорошее дело, но почему бы не попробовать обойтись без них.\n",
        "\n",
        "Удалите строки, содеражащие пропуски. Произведите <code>one-hot</code> кодировние нечисловых признаков, например, с помощью <code>pd.get_dummies(drop_first=True)</code>.\n",
        "\n",
        "Введите число полученных признаков."
      ],
      "metadata": {
        "id": "l7IkfsKoHlza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy.dropna(inplace=True)\n",
        "df_copy.reset_index(drop= True , inplace= True )\n",
        "data_encoded = pd.get_dummies(df_copy, drop_first=True)\n",
        "\n",
        "print(\"Число полученных признаков:\", data_encoded.shape[1])\n",
        "# тут почему-то ответ 75, хз почему\n",
        "df_copy"
      ],
      "metadata": {
        "id": "8zBk0YF9I7co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучите модель классификации аналогично тому, как это было проделано для базовой модели. Вычислите <code>f1_score()</code> модели.\n",
        "\n"
      ],
      "metadata": {
        "id": "ntH0eA3JLAp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_encoded = data_encoded.drop('label', axis=1)\n",
        "y_encoded = data_encoded['label']\n",
        "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(\n",
        "    X_encoded, y_encoded, test_size=0.2, random_state=27, stratify=y_encoded)\n",
        "\n",
        "# Нормируем данные через MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_encoded_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_test_encoded_scaled = scaler.transform(X_test_encoded)\n",
        "\n",
        "model_encoded_scaled = KNeighborsClassifier()\n",
        "model_encoded_scaled.fit(X_train_encoded_scaled, y_train_encoded)\n",
        "\n",
        "y_pred_encoded_scaled = model_encoded_scaled.predict(X_test_encoded_scaled)\n",
        "\n",
        "f1_encoded_scaled = f1_score(y_test_encoded, y_pred_encoded_scaled)\n",
        "\n",
        "print(\"F1 score на преобразованных и нормализованных данных:\", f1_encoded_scaled)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_encoded, y_pred_encoded_scaled, digits=4))"
      ],
      "metadata": {
        "id": "cfvX8LFwLS2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность модели увеличилась по сравнению с моделью, которая использовала только числовые признаки."
      ],
      "metadata": {
        "id": "YEQxNYjQL7lv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Заполнение пропущенных значений***\n",
        "\n",
        "Возможно точность еще повысится, если задействовать строки с пропущенными значениями. Используя исходный датасет (без колонок <code>education</code> и <code>marital-status</code>), заполните пропуски самым часто встречающимся значением в рамках столбца."
      ],
      "metadata": {
        "id": "t9-DCq5wMHj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_copy2 = data.copy()\n",
        "df_copy2.replace('?', pd.NA, inplace=True)\n",
        "\n",
        "data_filled = df_copy2.fillna(df_copy2.mode().iloc[0])\n",
        "\n",
        "# Повторно проверяем, есть ли пропущенные значения\n",
        "missing_values_after_filling = data_filled.isnull().sum().sum()\n",
        "print(\"Число пропущенных значений после заполнения:\", missing_values_after_filling)\n"
      ],
      "metadata": {
        "id": "oTetZAB6OVXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее по уже знакомому сценарию: <code>one-hot</code>, <code>split</code>, <code>scaling</code>, обучение и оценка.\n",
        "\n",
        "Вычислите <code>f1_score()</code> модели."
      ],
      "metadata": {
        "id": "HCSjgKyTPl_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoded_filled = pd.get_dummies(data_filled, drop_first=True)\n",
        "\n",
        "# Разбиваем на обучающую и тестовую выборки с учетом стратификации\n",
        "X_filled_encoded = data_encoded_filled.drop('label', axis=1)\n",
        "y_filled_encoded = data_encoded_filled['label']\n",
        "X_train_filled_encoded, X_test_filled_encoded, y_train_filled_encoded, y_test_filled_encoded = train_test_split(\n",
        "    X_filled_encoded, y_filled_encoded, test_size=0.2, random_state=27, stratify=y_filled_encoded)\n",
        "\n",
        "# Нормируем данные через MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_filled_encoded_scaled = scaler.fit_transform(X_train_filled_encoded)\n",
        "X_test_filled_encoded_scaled = scaler.transform(X_test_filled_encoded)\n",
        "\n",
        "# Обучаем модель KNeighborsClassifier с параметрами по умолчанию на нормализованных данных\n",
        "model_filled_encoded_scaled = KNeighborsClassifier()\n",
        "model_filled_encoded_scaled.fit(X_train_filled_encoded_scaled, y_train_filled_encoded)\n",
        "\n",
        "# Предсказываем на нормализованных тестовых данных\n",
        "y_pred_filled_encoded_scaled = model_filled_encoded_scaled.predict(X_test_filled_encoded_scaled)\n",
        "\n",
        "# Вычисляем f1_score модели на нормализованных данных\n",
        "f1_filled_encoded_scaled = f1_score(y_test_filled_encoded, y_pred_filled_encoded_scaled)\n",
        "\n",
        "# Выводим f1_score и classification_report\n",
        "print(\"F1 score на преобразованных и нормализованных данных:\", f1_filled_encoded_scaled)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_filled_encoded, y_pred_filled_encoded_scaled, digits=4))"
      ],
      "metadata": {
        "id": "pSvtbFdxQOqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Проклятие размерности***\n",
        "\n",
        "В последнем пункте был получен набор данных, содержащий 76 признаков (кстати, попробуйте объяснить, почему в случае удаления строк число признаков в итоге оказалось равным 75), что является достаточным для того, чтобы столкнуться с так называемым проклятием размерности.\n",
        "\n",
        "Для того, чтобы классификатор давал более качественные результаты, имеет смысл более внимательно и вдумчиво поработать с признаками с учетом проклятия размерности. Например, вернуть в рассмотрение признаки <code>education-num</code> и <code>marital-status</code>. А также более глубоко вникнуть в саму природу признаков."
      ],
      "metadata": {
        "id": "tI6RqgHARXWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3"
      ],
      "metadata": {
        "id": "IMhPg5jAfKOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "R-ihj6O_nhy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('adult_data_train.csv')\n",
        "data_pred = pd.read_csv('adult_data_reserved.csv')\n",
        "# Удаляем колонки 'education' и 'marital-status'\n",
        "# data_train = data_train.drop(['education', 'marital-status'], axis=1)\n",
        "# data_pred = data_pred.drop(['education', 'marital-status'], axis=1)\n",
        "print(data_train.columns)\n",
        "print(data_pred.columns)\n",
        "print(data_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vty4PC0ZouOg",
        "outputId": "921013f7-6e69-4f17-814b-f479c4e3301d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
            "       'label'],\n",
            "      dtype='object')\n",
            "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
            "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
            "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'],\n",
            "      dtype='object')\n",
            "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
            "0   32    Private   37210     Bachelors             13  Married-civ-spouse   \n",
            "1   43    Private  101950       Masters             14       Never-married   \n",
            "2   20          ?  122244       HS-grad              9       Never-married   \n",
            "3   40  Local-gov   24763  Some-college             10            Divorced   \n",
            "4   24    Private  113936     Bachelors             13       Never-married   \n",
            "\n",
            "         occupation   relationship   race     sex  capital-gain  capital-loss  \\\n",
            "0   Exec-managerial        Husband  White    Male             0             0   \n",
            "1   Exec-managerial  Not-in-family  White  Female             0             0   \n",
            "2                 ?  Not-in-family  White  Female             0             0   \n",
            "3  Transport-moving      Unmarried  White    Male          6849             0   \n",
            "4    Prof-specialty      Own-child  White    Male             0             0   \n",
            "\n",
            "   hours-per-week native-country  label  \n",
            "0              45  United-States      1  \n",
            "1              45  United-States      0  \n",
            "2              28  United-States      0  \n",
            "3              40  United-States      0  \n",
            "4              40  United-States      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.replace('?', pd.NA, inplace=True)\n",
        "data_pred.replace('?', pd.NA, inplace=True)\n",
        "\n",
        "# Удаление строк с пропущенными значениями в df_train\n",
        "data_train.dropna(inplace=True)\n",
        "data_train.reset_index(drop=True, inplace=True)\n",
        "# data_train.fillna(data_pred.mode().iloc[0], inplace=True)\n",
        "\n",
        "# # Удаление строк с пропущенными значениями в df_pred\n",
        "# data_pred.dropna(inplace=True)\n",
        "# data_pred.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n",
        "# data_train.fillna(data_train.mode().iloc[0])\n",
        "data_pred.fillna(data_pred.mode().iloc[0], inplace=True)\n",
        "\n",
        "\n",
        "for column in data_pred.columns:\n",
        "    # Печатаем название текущего столбца\n",
        "    print(f\"Processing column: {column}\")\n",
        "\n",
        "    # Проходимся по каждому значению в текущем столбце\n",
        "    for i, value in enumerate(data_pred[column]):\n",
        "      if value not in data_train[column].values:\n",
        "        most_frequent_value = data_pred[column].mode().iloc[0]\n",
        "        data_pred.at[i, column] = most_frequent_value\n",
        "\n",
        "data_pred.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E56nW14Lny84",
        "outputId": "a4be8d6a-7115-44fa-fc7a-6e314ffb3440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing column: age\n",
            "Processing column: workclass\n",
            "Processing column: fnlwgt\n",
            "Processing column: education\n",
            "Processing column: education-num\n",
            "Processing column: marital-status\n",
            "Processing column: occupation\n",
            "Processing column: relationship\n",
            "Processing column: race\n",
            "Processing column: sex\n",
            "Processing column: capital-gain\n",
            "Processing column: capital-loss\n",
            "Processing column: hours-per-week\n",
            "Processing column: native-country\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
              "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
              "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Применение LabelEncoder к каждому категориальному столбцу\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = data_train.drop('label', axis=1).columns\n",
        "for column in categorical_columns:\n",
        "    data_train[column] = label_encoder.fit_transform(data_train[column])\n",
        "    data_pred[column] = label_encoder.transform(data_pred[column])\n",
        "\n",
        "# Разделение на признаки (X) и целевую переменную (y)\n",
        "X_train = data_train.drop('label', axis=1)\n",
        "y_train = data_train['label']\n",
        "X_test = data_pred[X_train.columns]  # Используем только признаки из X_train\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели\n",
        "model = KNeighborsClassifier(n_neighbors=11, weights='distance')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Предсказание меток классов для данных для предсказания\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Выводим массив y_pred с числами, разделенными запятой\n",
        "print(len(y_pred))\n",
        "print(', '.join(map(str, y_pred)))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB5wlqfsGNPH",
        "outputId": "86e3951a-ac8e-478b-8104-1ad9c3747c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6513\n",
            "0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Преобразование категориальных признаков в числовые через one-hot encoding\n",
        "# data_train_encoded = pd.get_dummies(data_train, drop_first=True)\n",
        "# data_pred_encoded = pd.get_dummies(data_pred, drop_first=True)\n",
        "\n",
        "# missing_columns = set(data_train_encoded.columns) - set(data_pred_encoded.columns)\n",
        "# for column in missing_columns:\n",
        "#     data_pred_encoded[column] = 0\n",
        "\n",
        "# # Разделение на признаки (X) и целевую переменную (y)\n",
        "# X_train = data_train_encoded.drop('label', axis=1)\n",
        "# y_train = data_train_encoded['label']\n",
        "# X_test = data_pred_encoded[X_train.columns]  # Используем только признаки из X_train\n",
        "\n",
        "# scaler = MinMaxScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # Создание и обучение модели\n",
        "# model = KNeighborsClassifier(n_neighbors=11, weights='distance')\n",
        "# model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# # Предсказание меток классов для данных для предсказания\n",
        "# y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "# # Выводим массив y_pred с числами, разделенными запятой\n",
        "# print(len(y_pred))\n",
        "# print(', '.join(map(str, y_pred)))\n",
        "# print()"
      ],
      "metadata": {
        "id": "qCiXRsxXp3Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_dummies + замена средним = 0.614809782609\n",
        "# get_dummies + замена средним + замена новых =\n",
        "# get_dummies + удаление nan в train + замена nan в pred = 0.623169107856\n",
        "# get_dummies + удаление nan в train + замена nan в pred + замена новых = 0.620342396777\n",
        "# get_dummies + удаление nan в train + замена nan в pred + удаление 2х столбцов = 0.617028380634\n",
        "\n",
        "# get_dummies + удаление nan в train + замена nan в pred + замена новых + 11 соседей = 0.631364562118\n",
        "#* LabelEncoder + удаление nan в train + замена nan в pred + замена новых + 11 соседей  = 0.668839634941\n"
      ],
      "metadata": {
        "id": "HZSN5VgLtXrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 4"
      ],
      "metadata": {
        "id": "-c8fbFrtakZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "tnasDRzObYcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Данные классификации\n",
        "letters_spam = 23\n",
        "letters_not_spam = 25\n",
        "words_spam = 161\n",
        "words_not_spam = 193\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'word': ['Investment', 'Refund', 'Online', 'Million', 'Coupon', 'Prize', 'Access', 'Bill', 'Bonus', 'Free'],\n",
        "    'spam_amount': [10, 8, 1, 13, 31, 10, 9, 0, 34, 45],\n",
        "    'not_spam_amount': [36, 0, 16, 9, 2, 5, 6, 16, 16, 87]\n",
        "    })\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "f_SiLLnaavcg",
        "outputId": "93c7edd3-d90b-4eef-fe83-1696fb75dfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word  spam_amount  not_spam_amount\n",
              "0  Investment           10               36\n",
              "1      Refund            8                0\n",
              "2      Online            1               16\n",
              "3     Million           13                9\n",
              "4      Coupon           31                2\n",
              "5       Prize           10                5\n",
              "6      Access            9                6\n",
              "7        Bill            0               16\n",
              "8       Bonus           34               16\n",
              "9        Free           45               87"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-102351e9-c1ff-438b-b878-0bb8b1b5f855\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>spam_amount</th>\n",
              "      <th>not_spam_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Investment</td>\n",
              "      <td>10</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Refund</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Online</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Million</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coupon</td>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Prize</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Access</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bill</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bonus</td>\n",
              "      <td>34</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Free</td>\n",
              "      <td>45</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-102351e9-c1ff-438b-b878-0bb8b1b5f855')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-102351e9-c1ff-438b-b878-0bb8b1b5f855 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-102351e9-c1ff-438b-b878-0bb8b1b5f855');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9a19916-0ae8-436b-bc89-a001f667b248\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9a19916-0ae8-436b-bc89-a001f667b248')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9a19916-0ae8-436b-bc89-a001f667b248 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Общее количество уникальных слов\n",
        "V = len(df)\n",
        "text = \"Free Offer Access Purchase Prize Bonus Online\"\n",
        "words_in_text = text.split()\n",
        "r = len([word for word in words_in_text if word not in df['word'].values])\n",
        "\n",
        "# Общее количество слов в спаме и не спаме\n",
        "total_words_spam = words_spam\n",
        "total_words_not_spam = words_not_spam\n",
        "\n",
        "# Рассчитываем вероятности появления каждого слова в спаме и не спаме\n",
        "\n",
        "df['prob_word_spam'] = (1 + df['spam_amount']) / (V + r + total_words_spam)\n",
        "df['prob_word_not_spam'] = (1 + df['not_spam_amount']) / (V + r + total_words_not_spam)\n",
        "\n",
        "# Вероятности быть спамом или не спамом\n",
        "P_spam = letters_spam / (letters_spam + letters_not_spam)\n",
        "P_not_spam = letters_not_spam / (letters_spam + letters_not_spam)"
      ],
      "metadata": {
        "id": "wI4KmoqCwDR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_offer_spam = (1 + 0) / (V + r + total_words_spam)\n",
        "p_offer_not_spam = (1 + 0) / (V + r + total_words_not_spam)\n",
        "p_purches_spam = (1 + 0) / (V + r + total_words_spam)\n",
        "p_purches_not_spam = (1 + 0) / (V + r + total_words_not_spam)\n",
        "\n",
        "\n",
        "log_prob_spam = np.log(P_spam) + np.log(p_offer_spam) +np.log(p_purches_spam) + np.sum(np.log(df.loc[df['word'].isin(words_in_text), 'prob_word_spam']))\n",
        "log_prob_not_spam = np.log(P_not_spam) + np.log(p_offer_not_spam) +np.log(p_purches_not_spam) + np.sum(np.log(df.loc[df['word'].isin(words_in_text), 'prob_word_not_spam']))\n",
        "\n",
        "# Классификация\n",
        "classified_as_spam = log_prob_spam > log_prob_not_spam\n",
        "\n",
        "words_letter_spam = np.sum(df.loc[df['word'].isin(words_in_text), 'spam_amount'])\n",
        "\n",
        "p_full_spam = 1/ (1 + math.exp(log_prob_not_spam - log_prob_spam))\n",
        "\n",
        "# Ответы\n",
        "print(f'Вероятность того, что письмо является спамом, исходя из тренировочного набора данных: {P_spam}')\n",
        "print(f'Вычислите F(«спам»):{log_prob_spam}')\n",
        "print(f'Вычислите F(«не спам»):{log_prob_not_spam}')\n",
        "print(f\"Вероятность, что письмо является спамом:{p_full_spam}\")\n",
        "\n",
        "\n",
        "# Выводим результат классификации\n",
        "if classified_as_spam:\n",
        "    print(\"Текст классифицирован как 'спам'\")\n",
        "else:\n",
        "    print(\"Текст классифицирован как 'не спам'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb-BhLpG7Vvi",
        "outputId": "f162b7c4-9105-4c29-df56-9b984a5b4ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вероятность того, что письмо является спамом, исходя из тренировочного набора данных: 0.4791666666666667\n",
            "Вычислите F(«спам»):-24.031130952132322\n",
            "Вычислите F(«не спам»):-24.031961919134538\n",
            "Вероятность, что письмо является спамом:0.5002077417386\n",
            "Текст классифицирован как 'спам'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 5"
      ],
      "metadata": {
        "id": "rYaNiwC9JYX3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-_hAqChJeYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}